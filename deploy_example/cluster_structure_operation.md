# 클러스터 구조 및 운영 정책
##### 작성: 권영호 (mr.kwon05@gmail.com)
##### last modified: 2021.06.14
##### Elasticsearch version: 7.13
## About
- elasticsearch cluster 구조 기록
- 고가용성 및 성능을 위한 정책 사항 기록
- 위 작업 진행 사항 히스토리 기록
- 클러스터/노드 구성 요소(노드, 인덱스, 샤드)에 대한 상세 개념은 [Elasticsearch시스템구조](https://esbook.kimjmin.net/03-cluster) 참고
- 노드에 대한 것은 [별도 파일에 정리함](./about_node.md)

## 클러스터 운영 고려사항
### [성능,안정성] 시스템최적화
#### JVM 옵션
- 이미 엘라스틱서치에서 JVM 옵션 값을 튜닝 및 최적화해서 제공함
- 최대한 기본 설정값 건들이지 말고, jvm.option 파일에서 수정가능한 Xms, Xmx 사이즈만 32GB 이하로 설정하면됨
- Compressed OOP 사용을 위해 32GB 이하로 설정하지만 정확한 Limit 값은 JVM 버전, 플랫폼에 따라 달라짐
    - JVM 실행 후 UseCompressedOops 플래그 값이 true 인 값을 확인해야함
    ```shell
    # 32GB 최대 힙크기 일 때의 결과 확인 31744=31GB
    java -Xmx32768m -XX:+PrintFlagsFinal -version | grep UseCompressedOops
    # Zero-Based Compressed OOP 동작 가능 메모리 크기 조회
    java -Xmx31744m -XX:+PrintFlagsFinal -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode 2>/dev/null | grep UseCompressed|grep Oops
    ```
    ```shell
    # 엘라스틱서치 노드 실행 시 Compressed OOP 동작여부를 로그로 확인 가능
    [2021-12-16 13:53:33,417][INFO ][env][~~~] heap size [~~~mb], compressed ordinary object pointers [true]
    ```
    - 그냥 속편하게 31GB 이하로 설정해서 사용하는걸 추천

- 힙크기 설정 시 고려할 점
    - 권장사항은 전체 메모리의 50% && 32GB 이하
    - 고성능 메모리를 가진 서버에서는 한 서버에서 여러 인스턴스(노드)를 운영
    ```
    총 메모리 : 128GB
    운영체제 : 64GB
    엘라스틱서치 인스턴스 수: 2개 (각각 32GB)
    ```
    - 전문 검색이 주목적이면 운영체제에 많은 메모리를 남겨놓음 (루씬은 시스템 캐시를 통해 메모리를 최대한 사용할 수 있음)
    ```
    총 메모리 : 128GB
    운영체제 : 96GB
    엘라스틱서치 인스턴스 수: 1개 (각각 32GB)
    ```
    - 일반적인 데이터 필드 (Not Analyzed)에서 정렬/집계 작업을 많이 수행하는 경우
        - 숫자, 날짜, geo_point, keyword 같은 데이터 타입의 경우 별도의 분석과정을 거치지 않고, 힙 공간은 거의 사용되지 않음
    ```
    총 메모리 : 128GB
    운영체제 : 96GB
    엘라스틱서치 인스턴스 수: 1개 (각각 32GB)
    ```
    - 전문(Full Text) 필드에서 정렬/집계 작업을 많이 수행하는 경우
        - 힙메모리 많이 사용
        - 인스턴스 여러개 생성
    ```
    총 메모리 : 128GB
    운영체제 : 64GB
    엘라스틱서치 인스턴스 수: 2개 (각각 32GB)
    ```
#### 하나의 물리 서버에서 다수의 노드를 실행 시 
- 하나의 물리서버에 다수의 인스턴스가 실행될 경우 고가용성에 문제가 생길 수 있으므로
- 아래 옵션을 활성화하여 고가용성 확보 필요 
```yml
# 프라이머리 샤드와 레플리카 샤드가 같은 서버에 배치되는 것을 방지
cluster.routing.allocation.same_shard.host: true
```
#### 메모리 스와핑
- 메모리 스와핑: 사용되지 않는 물리메모리를 디스크로 스왑(Swap)-> 가상메모리의 일부 내용을 디스크로 쓰기 위해 디스크의 일정 영역을 스왑 영역으로 만듬. (이때 일어나는 동기화 작업에 의해 순간적으로 시스템 성능 저하 또는 장애가 발생)
- 메모리를 많이 사용하는 엘라스틱서치 특성상 스와핑 작업에 의해 문제가 발생할 수 있음
- 엘라스틱서치에서는 스와핑이 절대 발생하지 않게 하는 편이 좋음
- 스와핑 관리 방법
    1. 스와핑 비활성화
        - 시스템을 엘라스틱서치 노드 전용으로 사용하는 것이 가능한 경우
        - 루트 권한으로 sawpoff 명령어로 일시적인 스와핑 비활성화 또는 /etc/fstab 설정 파일 수정
        ```shell
        sudo swapoff - a
        vi /etc/fstab
        ```
    1. 스와핑 최소화
        - 스와핑을 완전히 비활성화할 수 없는 상황이라면 스와핑 주기를 조절, 발생 빈도를 최소화
        - vm.swappiness값 1로 설정 시 최대한 이용하지 않겠다는 뜻
        - 운영체제 메모리 관리 차원에서 필요하다고 판단되면 스와핑이 일어날 수 있음
        ```shell
        # vm.swappiness 정보확인
        cat /proc/sys/vm/swappiness
        # root권한으로 syctl 값을 이용해 설정 가능
        sudo sysctl vm.swappiness=1
        ```
    1. memory_lock 설정
    - 엘라스틱서치의 환경설정으로 제공하고 있는 bootstrap.memory_lock 속성 true 설정
    - 활성화 시 mlockall() 함수와 동일한 방식으로 애플리케이션 차원에서 스와핑을 최대한 방지 가능
        - mlockall(): 커널 수준에서 제공하는 저수준 함수. 호출한 프로세스의 페이징을 금지시키고, 모든 메모리가 RAM에 상주하는 것을 바장. 어플리케이션이 최초 실행될 때 할당받은 메모리를 스와핑하지 못하도록 강제함
    ```yml
    # $ES_HOME/config/elasticsearch.yml
    bootstrap.memory_lock: true
    ```
    - memory lock 이 정상적으로 수행되는지 엘라스틱서치 실행 후 반드시 확인 (실행 시 memory_lock 오류 발생하더라도 무시하고 실행될 수 있음)
    ```
    GET _nodes?filter_path=**.mlockall
    ```
    - 대표적으로 RLIMIT_MEMLOCK값이 낮아서 실패하는 경우가 생김
        - ulimit 값을 unlimited 로 설정
        - /etc/security/limits.conf 파일에 유저명 - memlock unlimited 추가
        
#### 시스템 튜닝 포인트
- ulimit: 리눅스 운영체제 리소스 제한 설정
```shell
# 조회
ulimit -a
# 수정
ulimit -옵션 최대값
# 영구 적용
vi /etc/security/limits.conf

# 수정 검토 값
# open files: 생성할 수 있는 파일 디스크립터 개수, 최소 65536개 이상
계정명  -   nofile  81920
# 설정 시 오류 발생 시 -> 커널에서도 내부적으로 설정가능한 파일 개수를 넘어가면 에러. 에러 발생 시 커널 레벨에서 먼저 늘려야함
cat /proc/sys/fs/file-max

# Max Thread 한계 설정
# ulimit -a 시 max user processes 값으로 확인 가능
계정 명 -   nproc   81920
```
- sysctl: 커널 설정 설정 (민감한 정보이므로 수정에 주의) 
```shell
# 조회
/sbin/sysctl -a
# 수정
sysctl -w 파리미터명 = 파라미터 값
# 영구 적용
vi /etc/sysctl.conf

# 수정 검토 값
# vm.max_map_count
vm.max_map_count=262144
```

### [성능,안정성] 샤드 최적화
- 인덱스를 생성할 때 설정된 샤드(프라이머리샤드)의 개수는 변경이 안됨
- 샤드 종류
    - 프라이머리 샤드: CRUD 발생 샤드
    - 레플리카 샤드: 장애복구용 샤드 (R-읽기 기능도 수행)
    ```
    # shard 개수 지정
    PUT /index_name
    {
        "settings": {
            "index": {
                "number_of_shards": 5,
                "number_of_replicas": 1
            }
        }
    }
    ```
- 샤드의 개수 결정
    - 프라이머리 샤드의 개수에 대해
        - 전체 클러스터 상에서는 무제한. 인덱스별로는 1024개 제한.
        - 마스터 노드에서 샤드를 관리 -> 샤드 개수가 많아지면 마스터 노드의 부하 증가 -> 마스터 노드가 느려지면 검색/색인 작업도 느려짐 & 메모리 부족으로 장애 발생 시 클러스터 장애 발생 위험있음(마스터노드는 관리 데이터를 모두 메모리에 올려서 작업)
        - 검색 성능은 프라이머리 샤드의 개수가 많을 수록 좋아짐
        - 개별 샤드의 물리적인 크기가 클 수록 장애 발생 시 복구에 시간이 더 오래걸림
        - 적절한 개수는?
            - 엘라스틱서치에서는 샤드 1개가 물리적으로 50GB를 넘지 않도록 권장
            - 미래에 저장될 데이터의 크기를 추정하여 샤드 1개가 50GB 정도의 크기를 가지도록 설정
            - 결론은: 하드웨어, 데이터 크기와 복잡성, 검색 쿼리의 유형, 집계의 규모 등 성능에 영향을 미치는 변수를 가지고 충분한 테스트를 통해 결정
    - 레플리카 샤드의 개수에 대해
        - 레플리카샤드가 너무 많으면 색인 성능이 떨어짐 (레플리카 샤드에도 자료를 기록/삭제해야하기 때문)
        - 읽기 분산이 중요하면 레플리카 세트의 수를 늘리고 (레플리카 샤드에서도 읽기 작업이 수행되기 때문)
        - 빠른 색인이 중요하면 레플리카 세트의 수를 최소화
        - 최초 서비스에는 레플리카의 수를 최소화. 이후 모니터링 결과에 따라 탄력적으로 개수 조절
    - 인덱스에서 생성 가능한 최대 문서 수 = 2조개
        - (루씬에서 생성 가능한 최대 문서 수: Java.lang.Integer.MAX_VALUE-128 = 약20억) * (인덱스 생성 시 설정가능한 샤드의 수: 1024) = 20억 * 1024 = 약 2조
- 샤드 개수 변경이 필요하면 새로운 인덱스 생성하고 재색인해야함
    - reindex API 사용
    ```
    POST _reindex
    {
        "source": {
            "index": "index_name"
        },
        "dest": {
            "index": "new_index_name"
        }
    }
    ```

### [안정성] 기타
- translog 크기가 항상 일정 크기 이하 유지할 수 있도록 모니터링/관리가 필요

### [성능] Refresh, Flush, Optimize API 설정 (=> 루씬 flush, commit, merge 주기 최적화)
- Refresh
    - 새로 추가한 데이터의 검색이 가능하게함 (인메모리 버퍼에 있는 데이터를 기록)
    - 기본값으로 1초마다 한 번씩 Refresh 수행됨
    - 기본 설정된 주기 변경은 비추천 (전체 성능에 직접적인 영향을 미침)
    - 대신 대량 색인 시 임시로 Refresh 작업을 비활성화하고 색인 작업 끝나고 원래 설정으로 복구하는 방법 추천
    ```
    # Refresh 비활성화
    PUT /index_name/_settings
    {
        "index":{
            "refresh_interval": "-1"
        }
    }

    # Refresh 원래 주기(1초)로 설정
    PUT /index_name/_settings
    {
        "index":{
            "refresh_interval": "1s"
        }
    }
    ```
- Flush
    - 루씬의 commit 작업 수행하고 새로운 Translog시작
    - Translog: 샤드의 장애 복구를 위해 제공되는 파일.
        - 모든 변경사항을 Translog에 먼저 기록 -> 루씬 commit 정상 수행 -> 변경사항 디스크 물리적 기록 -> Translog 반영 분 삭제
    - 기본값: 5초 (변경 비추천)
- Optimize API
    - 루씬의 Merge 작업 강제 수행 (파편화된 세그먼트 통합)
    ```
    # 샤드의 세그먼트를 설정된 개수로 강제 병합 가능
    POST /index_name/_forcemerge?max_num_segments=1
    ```
- 상세설명
    - 엘라스틱서치의 샤드는 루씬인덱스의 확장이고, 루씬인덱스의 자료구조인 세그먼트의 집합으로 볼 수 있음
    - 세그먼트는 역색인 구조의 불변성(Immutablity) 자료구조임 (리소스 절감, 동시성 문제 회피, 속도 향상 등의 이유로 사용)
    - 불변성 유지를 위해 자료의 추가/수정/삭제가 이뤄질 시 새로운 세그먼트를 생성하는 방식으로 운영됨
    - 세그먼트들은 백그라운드에서 주기적으로 통합됨 (통합과정에서 삭제 처리된 데이터의 실제 물리적인 삭제도 이루어짐)
    - 루씬에서는 세그먼트 관리하는 작업을 아래와 같이 나눌 수 있음
    - flush 작업
        - 세그먼트가 생성된 후 검색이 가능해지도록 수행하는 작업
        - write() 함수로 동기화 (커널 시스템 캐시에만 데이터 생성됨 => 캐시에 생성해놓았다가 물리적 - 성능상 이점 but 시스템이 갑자기 다운되거나 하면 자료 유실 위험있음)
    - commit 작업
        - 커널 시스템 캐시의 내용을 물리적인 디스크로 쓰는 작업
        - 많은 리소스 필요함
    - merge 작업
        - 다수 세그먼트 통합 작업
        - 삭제 처리된 데이터의 실제 물리적인 삭제
        - 검색할 세그먼트 수가 줄어들어 검색 성능이 좋아짐
    
## 운영 노하우
### 노드 관리
- 마스터에 장애가 발생 시 클러스터 전체 영향을 미치므로, 다수의 마스터 운영
- 데이터 노드는 CRUD 작업, 검색, 집계 등 대량의 리소스를 사용하기 때문에 고성능 CPU, 메모리 갖춘 서버 사용
- 규모가 큰 클러스터에서는 안정성을 위해 전용 Coordination 노드 별도 구축하는 편이 좋음
    - 각 데이터 노드에게 전달받은 데이터 병합 과정에서 많은 양의 메모리가 필요하고, 작업 수행 중에 다른 노드로서의 역할에 문제가 생길 수 있기 때문에
- 규모가 커질 예정이거나 크면 마스터 노드와 데이터 노드는 분리해서 운영
    - 마스터 노드는 많은 리소스는 필요 없으므로 기본 장비에서 운영
    - 데이터 노드는 고성능 장비에서 운영
    - 집계 연산이 많거나, 통제가 불가능한 상황일 때는 Coordination 노드를 별도로 구축
        - 일정 규모 이상에서는 검색용, 색인용, 집계용 노드를 별도로 분리해서 구축해도 좋음. 하지만 너무 많은 Coordination 노드는 마스터 노드에게 큰 부담을 줄 수 있음
### 클러스터 관리
#### 런타임 환경설정 변경
- _cluster/settings API로 환경설정 동적 변경 가능 (elasticsearch.yml 으로 변경 시 인스턴스 재시작해야함)
- API에서 영구 설정 변경 시 elasticsearch.yml 명시 설정 내용보다 우선순위가 높음
- 단일 서버 내용은 elasticsearch.yml에 공통 설정은 API 활용하면 편함
```python
# 영구 설정
PUT /_cluster/settings
{
    "persistent" : {
        "indices.recovery.max_bytes_per_sec": "50mb"
    }
}
# 임시 설정
PUT /_cluster/settings
{
    "transient" : {
        "indices.recovery.max_bytes_per_sec": "50mb"
    }
}
```
#### 태스크 조회
- _cluster/pending_tasks API:  대기 중 태스크 목록
- 병목 지점 알아내는데 도움
```
GET /_cluster/pending_tasks
```
- _tasks API: 실행 중 태스크 목록
```
GET /_tasks?nodes=NODE_ID
```
#### 노드 간 샤드 이동
- _cluster/reroute API
- 리소스 소모량 많고, 시간도 오래걸림(네트워크 전송)
```python
# 0 번 샤드를 node1 에서 node2로 이동하는 예
POST /_cluster/reroute
{
    "command" : [
        {
            "move": {
                "index" : "index_name",
                    "shard": 0,
                "from_node": "node1",
                    "to_node": "node2"
            }
        }
    ]
}
```

### 노드부트스트랩 과정
- 엘라스틱서치는 높은 안정성과 고가용성이 목표이기 때문에 리소스 사용량 및 제한이 많음
- 최적화 과정을 거치지 않으면 데이터 사이즈가 커지고, 시간이 지날 수록 문제점이 많이 발생함
- 부트스트랩 체크를 통해 필수 설정에 대한 검사를 시행 후 적절하게 설정되었을 떄 인스턴스가 실행될 수 있도로 강제함
- 개발모드/운영모드 구분하여, 개발모드에서는 부트스트랩 체크과정이 무시됨
    - 개발모드는 network.host 설정이 루프백(localhost)으로 설정된 경우
- 부트스트랩 체크 과정 상세 (버전마다 조금씩 차이가 있음. 보통 단계가 추가됨. 아래는 6.4 버전 기준 상세 과정임)
    1. 힙 크기 체크
        - JVM 기본 힙크기와 최대 힙크기가 같은지 검사
            - 시스템 운영 중에 힙 크기 조정이 일어나지 않도록
            - Memory Lock은 기본 힙 크기만큼 대상으로 하기 때문에, 두 값이 다르면 늘어난 힙 크기만큼 스와핑 대상이 될 수 있기 때문
    1. 파일 디스크립터 체크
        - 사용하는 파일 처리량이 매우 많음. 충분한 파일 디스크립터가 존재하는지 검사.
    1. 메모리 락 체크
        - JVM 가비지 컬렉션 시 힙 구성 메모리 페이지 조각 중 하나라도 디스크에 스왑 아웃이 되어 있다면, 이를 메모리에 다시 올리는 스왑 인 작업을 반드시 해야함. => 부담이 많이 됨 
        - 엘라스틱서치는 스와핑을 최대한 사용하지 않는 방향으로 설정되어야 하며, 따라서 힙에 할당된 메모리는 스와핑 대상이 되지 않도록 Memory Lock을 통해 잠그도록 권장함
    1. 최대 쓰레드 수 체크
        - 엘라스틱서치는 기능 별로 여러 단계의 모듈로 구성됨. 각 모듈은 큐와 쓰레드풀을 가지고, 많은 수의 쓰레드를 생성/관리함
        - 스레드를 생성할 수 있는 최대 쓰레드 수 확인 (최소 4096개 이상)
    1. 최대 가상 메모리 크기 체크 (unlimit 여부)
        - 인덱스 생성/관리를 위해 mmap을 이용해 메모리 매핑 수행
            - mmap을 이용하면 JVM을 통하지 않고 리눅스 커널로 직접 시스템 콜을 실행할 수 있음
        - mmap은 커널 레벨의 메모리를 직접 할당받아 애플리케이션의 가상 메모리 주소에 매핑해서 동작하기 때문에 메모리 크기에 제한이 없는 편이 좋음
    1. 최대 파일 크기 체크 (unlimit 여부)
        - 세그먼트 파일과 트랜스 로그 파일은 상황에 따라 수십 GB 이상으로 커질 수 있음
    1. mmap 카운트 체크
        - 최대 mmap 카운트가 262,114개 이상인지 확인
    1. 클라이언트 JVM 체크
        - Server JVM 으로 실행되었는지 확인 (Server JVM : 고성능 처리, Client JVM: 빠른 실행, 적은 메모리사용)
    1. Serial Collection 사용 여부 체크
        - JVM 가비지컬렉터 종류 중 Serial GC 컬렉터 사용여부 확인 (구식 가비지 컬렉터)
    1. 시스템 콜 필터 체크
        - 시스템 콜: 운영체제에서 유저모드와 커널모드 간 분리된 메모리 공간 간에 데이터 공유를 위해 사용
            - 임의 코드 실행 공격 막기 위해 시스템 콜 필터 제공함 (seccomp, seccomp-bpf 함수를 이용해 샌드박스 구현)
        - 보안을 위해 시스템 콜 필터 설치 여부 검사. 미지원 시 부트스트랩 항상 실패.
            - bootstrap.system_call_filter옵션 false로 설정할 수 있지만, 보안 측면에서 항상 시스템 콜 필터를 설치하는게 좋으므로, 운영체제가 미지원한다면 커널 업데이트를 통해 설치하는 편이 좋음
    1. OnError, OnOutOfMemoryError 체크 (해당 옵션이 없어야 함)
        - JVM 실행 시 위 에러가 발생하면 특정 명령/스크립트 실행하도록 설정할 수 있음
        - 이 옵션을 활성화하면 시스템 콜필터를 사용이 안되기 때문에 옵션 설정이 존재하는지 확인함
    1. Early-access 체크
        - 테스트 버전 JVM 사용여부 검사 (사용하면 안됨)
    1. G1GC 체크
        - G1GC 콜렉터 사용 시 JVM 버전 확인
            - 엘라스틱서치 기본 GC 방식 CMS
            - 초기버전의 자바 8에서 G1GC 수집기 활성화 될때 인덱스 손상 버그가 있었음
            - G1GC 방식 사용하고 싶으면 반드시 JDK 8u40 이후 릴리스 버전 사용해야함
        - G1 GC 적용과 JVM Upgrade에 대하여 [참고](https://brunch.co.kr/@alden/45)
    1. All Permission 체크
        - 보안 문제로 모든 리소스 접근 권한이 있지 않도록 검사